# quantize

Only support multi-modal encoders quantization in GGUF format, please use llama-quantize for llm quantization in llama.cpp
